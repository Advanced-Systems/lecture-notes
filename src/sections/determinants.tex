\subsection{Determinants}\label{subsec-determinants}

\begin{definition}\label{def-inductive-determinant}
	Let $A$ be a $n \times n$ matrix. We define the determinant inductively:
	\begin{align}
		\boxed{n=1}:A    & =\begin{pmatrix}
			a
		\end{pmatrix}\nonumber                                                              \\
		\implies \det(A) & =a                                                                                               \\\nonumber\\
		\boxed{n=2}:A    & =\begin{pmatrix}
			a_{11} & a_{12} \\
			a_{21} & a_{22}
		\end{pmatrix}\nonumber                                                              \\
		\implies \det(A) & =a_{11}a_{22}-a_{12}a_{21}                                                                       \\\nonumber\\
		\boxed{n=3}:A    & =\begin{pmatrix}
			a_{11} & a_{12} & a_{13} \\
			a_{21} & a_{22} & a_{23} \\
			a_{31} & a_{32} & a_{33}
		\end{pmatrix}\nonumber                                                              \\
		\implies \det(A) & =a_{11}M_{11}-a_{12}M_{12}+a_{13}M_{13}\nonumber                                                 \\
		                 & =a_{11}\begin{vmatrix}
			a_{22} & a_{23} \\
			a_{32} & a_{33}
		\end{vmatrix}-a_{12}\begin{vmatrix}
			a_{21} & a_{23} \\
			a_{31} & a_{33}
		\end{vmatrix}+a_{13}\begin{vmatrix}
			a_{21} & a_{22} \\
			a_{31} & a_{32}
		\end{vmatrix}
	\end{align}
	The determinant of a matrix obtained by eliminating the $i$'th row and the
	$j$'th column of $A$ is called the $ij$'th minor of $A$, and is denoted by $M_{ij}$.
	In general we can calculate the determinant through the formula\footnote{This
		is a simplified version of the Leibniz or Laplace formula to which we will come
		back later}
	\begin{equation}
		\boxed{A\in\mathcal{M}_n(\mathcal{F})}:\det(A) = \sum_{i=1}^n (-1)^{i+1} a_{1i}M_{1i}
	\end{equation}
\end{definition}

\begin{exm}\label{exm-eval-determinats}
	Calculate the determinant for the following matrices:
	\begin{enumerate}
		\item $A=\inlinematrix{5&6\\8&9}$
		\item $B=\inlinematrix{1&2&3\\4&5&6\\7&8&9}$
	\end{enumerate}
	\begin{flushleft}
		\textbf{Answer to 1}:
		\begin{align*}
			\det\begin{pmatrix}
				5 & 6 \\
				8 & 9
			\end{pmatrix} & =5\cdot9-6\cdot8 \\
			                              & =45-48           \\
			                              & =-3
		\end{align*}
	\end{flushleft}
	\begin{flushleft}
		\textbf{Answer to 2}:
		\begin{align*}
			\det\begin{pmatrix}
				1 & 2 & 3 \\
				4 & 5 & 6 \\
				7 & 8 & 9
			\end{pmatrix} & =1\begin{vmatrix}
				5 & 6 \\
				8 & 9
			\end{vmatrix}-2\begin{vmatrix}
				4 & 6 \\
				7 & 9
			\end{vmatrix}+3\begin{vmatrix}
				4 & 5 \\
				7 & 8
			\end{vmatrix} \\
			                               & =1(5\cdot9-6\cdot8)-2(4\cdot9-6\cdot7)+3(4\cdot8-5\cdot7)                            \\
			                               & =1(45-48)-2(36-42)+3(32-35)                                                          \\
			                               & =-3+12-9                                                                             \\
			                               & =0
		\end{align*}
	\end{flushleft}
\end{exm}

\begin{thm}\label{thm-determinant-transposed}
	Let $A$ be a square matrix. Then, $\det(A^T)=\det(A)$.
\end{thm}

\begin{crl}\label{crl-determinant-row-col-properties}
	From \pref{theorem}{thm-determinant-transposed} follows that every
	property of $\det(A)$ which is true for rows, is also true for columns.
\end{crl}

\begin{thm}\label{thm-determinant-row-col}
	One can evaluate the determinant by any row or column. If we use an even
	row or column, we have to start with a minus sign. Conversely, if we use an
	odd row or column, we have to start with a plus sign.
\end{thm}

\begin{exm}
	In this example we re-purpose the second matrix from \pref{example}{exm-eval-determinats}
	as an hands-on exercise to \pref{theorem}{thm-determinant-row-col}: Since we
	start at the 2nd column this time, we have to start with a minus sign:
	\begin{align*}
		\det\begin{pmatrix}
			1 & \boxed{2} & 3 \\
			4 & \boxed{5} & 6 \\
			7 & \boxed{8} & 9
		\end{pmatrix} & =-2\begin{vmatrix}
			4 & 6 \\
			7 & 9
		\end{vmatrix}+5\begin{vmatrix}
			1 & 3 \\
			7 & 9
		\end{vmatrix}-8\begin{vmatrix}
			1 & 3 \\
			4 & 6
		\end{vmatrix} \\
		                               & =-2(36-42)+5(9-21)-8(6-12)                                                            \\
		                               & =-2(-6)+5(-12)-8(-6)                                                                  \\
		                               & =12-60+48                                                                             \\
		                               & =0
	\end{align*}
\end{exm}

\begin{rem}
	It is recommended to evaluate the determinant with the row or column that
	contains the most zeros to cancel out the $ij$'th minor of $A$.
\end{rem}

\begin{exm}
	Let $A=\inlinematrix{1&4&0&3\\1&0&0&3\\1&2&0&1\\1&0&5&3}$. Then using the
	advice from the previous remark we can fairly quickly evaluate this determinant by
	\begin{align*}
		\det\begin{pmatrix}
			1 & 4 & \boxed{0} & 3 \\
			1 & 0 & \boxed{0} & 3 \\
			1 & 2 & \boxed{0} & 1 \\
			1 & 0 & \boxed{5} & 3
		\end{pmatrix} & =-5\begin{vmatrix}
			1         & 4         & 3         \\
			\boxed{1} & \boxed{0} & \boxed{3} \\
			1         & 2         & 1
		\end{vmatrix}                                            \\
		                               & =-5\left(-1\begin{vmatrix}
			4 & 3 \\
			2 & 1
		\end{vmatrix}-3\begin{vmatrix}
			1 & 4 \\
			1 & 2
		\end{vmatrix}\right) \\
		                               & =-5\left(-1(4-6)-3(2-4)\right)                                           \\
		                               & =-5(2+6)                                                                 \\
		                               & =-40
	\end{align*}
\end{exm}

\begin{thm}\label{thm-determinant-properties}
	This theorem is a collection of various properties related to determinants:
	\begin{enumerate}
		\item If one of the rows or columns is all zeros, then $\det(A)=0$.
		\item The determinant of a triangular matrix is the product of the main-diagonal entries.
		\item If we exchange two rows or two columns, the sign of the determinant changes.
		\item If $A$ has two equal rows or columns, then $\det(A)=0$.
		\item A common factor of a row or column can be taken out of the determinant.
		\item If one row or column is a multiple of another row or column, then $\det(A)=0$.
		\item If we add a scalar multiple of a row or column to another row or column, then
		      the determinant doesn't change
	\end{enumerate}
\end{thm}

\begin{rem}
	If we do row-operations, the determinant changes. You must pay attention to
	signs and scalars.
\end{rem}

\begin{thm}\label{thm-determinant-row-equivalent-zero}
	If $A$ and $B$ are row-equivalent, then $\det(A)=0 \Leftrightarrow \det(B)=0$.
\end{thm}

\begin{thm}\label{thm-square-matrix-properties-extended}
	In extension of \pref{theorem}{thm-square-matrix-properties} we add to the list:
	\begin{enumerate}
		\item[5.] The rows of $A$ are linearly independent.
		\item[6.] $\det(A)\neq0$.
	\end{enumerate}
\end{thm}

\begin{proof}
	Of \pref{theorem}{thm-square-matrix-properties-extended}.
	\begin{flushleft}
		$(1)\implies(6)$: Find the reduced row-echelon form of $A$, denoted by $C$.
		If $A$ is invertible, then by \pref{theorem}{thm-square-matrix-properties}
		(statement 3), $A$ is row-equivalent to the identity matrix $I$. But since
		the canonical form is unique, we can go a step further and say $C=I$.
		Hence, $\det(C)=\det(I)$. The identity matrix in particular is a triangular
		matrix, and by statement 2 of \pref{theorem}{thm-determinant-properties}
		we get that $\det(C)=1\neq0$.
	\end{flushleft}
	\begin{flushleft}
		$(6)\implies(1)$: As for the other direction of this proof recall that
		proving $(6)\implies(1)$ is equivalent to $\neg(1)\implies\neg(6)$. So,
		if $A$ is not invertible, then by \pref{theorem}{thm-square-matrix-properties},
		statement 2, then $\frank(A)<n$. This implies that at least one row in $C$
		is a zero-row. But by statement 1 of \pref{theorem}{thm-determinant-properties}
		this means that $\det(A)=0$. But since $A$ is row-equivalent to its inverse
		matrix $C$ this means in particular $\det(C)=0$.
	\end{flushleft}
\end{proof}

\begin{thm}\label{thm-product-of-matrices}
	For two square matrices $A$ and $B$ the following equation holds:
	\begin{equation}
		\det(AB)=\det(A)\det(B)
	\end{equation}
\end{thm}

\begin{crl}\label{crl-determinant-transposed}
	If $A$ is invertible, then
	\begin{equation}
		\det(A^{-1})=\frac{1}{\det(A)}
	\end{equation}
\end{crl}

\begin{proof}
	Of \pref{corollary}{crl-determinant-transposed}.
	\begin{flushleft}
		From $AA^{-1}=I$ and \pref{theorem}{thm-product-of-matrices} follows that
		\begin{align*}
			\det(AA^{-1}) & =\det(A)\det(A^{-1}) \\
			              & =1
		\end{align*}
		Therefore,
		\begin{equation*}
			\det(A^{-1})=\frac{1}{\det(A)}
		\end{equation*}
		This division is well-defined by \pref{theorem}{thm-square-matrix-properties-extended},
		statement 6, since $A$ is invertible.
	\end{flushleft}
\end{proof}
