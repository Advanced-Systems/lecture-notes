\subsection{Coordinate Vectors}\label{subsec-coordinate-vectors}

\begin{thm}\label{thm-basis-unique-linear-combination}
	Let $\mathcal{V}$ be a vector space and $\mathcal{B}=\{v_1,v_2,\dots,v_n\}$
	be a basis of $\mathcal{V}$. Then any element $v\in\mathcal{V}$ can be written
	uniquely as $v=\lambda_1v_1+\lambda_2v_2+\cdots+\lambda_nv_n$.
\end{thm}

\begin{proof}
	Of \pref{theorem}{thm-basis-unique-linear-combination}.
	\begin{flushleft}
		Assume that $v$ is not unique, \textit{i.e.} there exists at
		least one more linear combination of $v$ such that
		\begin{equation*}
			v=\lambda_1v_1+\lambda_2v_2+\cdots+\lambda_nv_n=\mu_1v_1+\mu_2v_2+\cdots+\mu_nv_n
		\end{equation*}
		Then
		\begin{equation*}
			0=(\lambda_1-\mu_1)v_1+(\lambda_2-\mu_2)v_2+\cdots+(\lambda_n-\mu_n)v_n
		\end{equation*}
		Note that all $v_i\in\mathcal{B}$ are linearly independent since they are
		elements of the basis of $\mathcal{V}$. By \pref{definition}{def-linear-independence}
		a linear combination of linear independent elements means that all coefficient
		are equal to zero. Therefore $\lambda_i-\mu_i=0\implies\lambda_i=\mu_i$
		for all $i\in\mathbb{N}$.
	\end{flushleft}
\end{proof}

\begin{definition}\label{def-coordinate-vector}
	Let $\mathcal{V}$ be a vector space and $\mathcal{B}=\{v_1,v_2,\dots,v_n\}$
	be a basis of $\mathcal{V}$. If
	\begin{equation*}
		v=\lambda_1v_1+\lambda_2v_2+\cdots+\lambda_nv_n,
	\end{equation*}
	then $\lambda_1,\lambda_2,\dots,\lambda_n$ are called the coordinates of
	$v$ with respect to $\mathcal{B}$ and are denoted by
	\begin{equation}
		[v]_\mathcal{B}=\begin{pmatrix}
			\lambda_1 \\
			\lambda_2 \\
			\vdots    \\
			\lambda_n
		\end{pmatrix}
	\end{equation}
\end{definition}

\begin{exm}
	Let $\mathcal{V}=\mathbb{R}^3$ and
	\begin{equation*}
		\mathcal{E}=\left\{
		\begin{pmatrix}
			1 \\0\\0
		\end{pmatrix},
		\begin{pmatrix}
			0 \\1\\0
		\end{pmatrix},
		\begin{pmatrix}
			0 \\0\\1
		\end{pmatrix}
		\right\}=\left\{
		e_1,e_2,e_3
		\right\}
	\end{equation*}
	Find the coordinate vector for $v=\inlinematrix{1\\2\\3}$
	\begin{flushleft}
		\textbf{Answer}: From
		\begin{equation*}
			v = e_1 + 2e_2 + 3e_3
		\end{equation*}
		follows that
		\begin{equation*}
			[v]_E=\begin{pmatrix}
				1 \\2\\3
			\end{pmatrix}
		\end{equation*}
	\end{flushleft}
\end{exm}

\begin{exm}
	Let $\mathcal{W}=\mathbb{R}^3$ and
	\begin{equation*}
		\mathcal{F}=\left\{
		\begin{pmatrix}
			1 \\1\\0
		\end{pmatrix},
		\begin{pmatrix}
			1 \\0\\1
		\end{pmatrix},
		\begin{pmatrix}
			0 \\1\\1
		\end{pmatrix}
		\right\}
	\end{equation*}
	be the basis of $\mathcal{W}$. A proof for linear independence was shown
	in a previous lecture in \pref{example}{exm-show-linearly-independency}.
	Furthermore, we have seen in \pref{example}{exm-vector-basis:2} that
	\begin{equation*}
		\begin{pmatrix}
			a \\b\\c
		\end{pmatrix}=
		\frac{a-c+b}{2}\begin{pmatrix}
			1 \\1\\0
		\end{pmatrix}+
		\frac{c-b+a}{2}\begin{pmatrix}
			1 \\0\\1
		\end{pmatrix}+
		\frac{b-a+c}{2}\begin{pmatrix}
			0 \\1\\1
		\end{pmatrix}
	\end{equation*}
	From this information we can derive that
	\begin{align*}
		\begin{pmatrix}
			1 \\2\\3
		\end{pmatrix} & =
		0\begin{pmatrix}
			1 \\1\\0
		\end{pmatrix}+
		1\begin{pmatrix}
			1 \\0\\1
		\end{pmatrix}+
		2\begin{pmatrix}
			0 \\1\\1
		\end{pmatrix}                              \\
		\implies
		[v]_\mathcal{F}            & =\begin{pmatrix}
			0 \\1\\2
		\end{pmatrix}
	\end{align*}
\end{exm}

\begin{exm}
	Let $\mathcal{V}=\mathcal{M}_2(\mathbb{R})$ and $\mathcal{E}$ the canonical
	basis of $\mathcal{V}$. Find the coordinate vector of the matrix
	$A=\inlinematrix{1&2\\3&4}$.
	\begin{flushleft}
		\textbf{Answer}:
		\begin{align*}
			\begin{pmatrix}
				1 & 2 \\
				3 & 4
			\end{pmatrix}=
			\begin{pmatrix}
				1 & 0 \\
				0 & 0
			\end{pmatrix}+
			2\begin{pmatrix}
				0 & 1 \\
				0 & 0
			\end{pmatrix}+
			3\begin{pmatrix}
				0 & 0 \\
				1 & 0
			\end{pmatrix}+
			4\begin{pmatrix}
				0 & 0 \\
				0 & 1
			\end{pmatrix}
		\end{align*}
		Therefore the coordinate vector of $A$ with respect to $\mathcal{B}$ is
		\begin{equation*}
			[A]_\mathcal{B}=\begin{pmatrix}
				1 \\2\\3\\4
			\end{pmatrix}\in\mathbb{R}^4
		\end{equation*}
	\end{flushleft}
\end{exm}

\begin{thm}\label{thm-coordinate-vector-properties}
	Let $\mathcal{V}$ be a vector space and $\mathcal{B}=\{v_1,v_2,\dots,v_n\}$
	be a basis of $\mathcal{V}$. Then for the following equations hold:
	\begin{enumerate}
		\item $[v_1+v_2]_\mathcal{B}=[v_1]_\mathcal{B}+[v_2]_\mathcal{B}$
		\item $[\lambda v]_\mathcal{B}=\lambda[v]_\mathbb{B}$
		\item $[v]_\mathcal{B}=0 \Leftrightarrow v=0$
	\end{enumerate}
	for all $\lambda\in\mathbb{B}$ and $v_1,v_2\in\mathcal{V}$.
\end{thm}

\begin{proof}
	Of \pref{theorem}{thm-coordinate-vector-properties}.
	\begin{flushleft}
		TODO
	\end{flushleft}
\end{proof}

\begin{thm}\label{thm-vector-coordinates-linear-independence}
	Let $\mathcal{V}$ a vector space with $\dim(\mathcal{V})=n$ where $\mathcal{B}$
	is a basis of this vector space. Then a set of elements $\{v_1,v_2,\dots,v_k\}$
	is linearly independent \textit{iff}
	$\{[v_1]_\mathcal{B},[v_2]_\mathcal{B},\dots,[v_k]_\mathcal{B}\}$ is linearly
	independent in the field $\mathcal{F}^n$.
\end{thm}

\begin{proof}
	Of \pref{theorem}{thm-vector-coordinates-linear-independence}.
	\begin{flushleft}
		\proofright: Assume that the vectors
		$\{[v_1]_\mathcal{B},[v_2]_\mathcal{B},\dots,[v_k]_\mathcal{B}\}$ are
		linearly independent. Take a linear combination such that
		\begin{equation*}
			\lambda_1[v_1]_\mathcal{B}+\lambda_2[v_2]_\mathcal{B}+\cdots+\lambda_k[v_k]_\mathcal{B}=0
		\end{equation*}
		From statement 2 of \pref{theorem}{thm-coordinate-vector-properties} follows that
		this is equivalent to
		\begin{equation*}
			[\lambda_1v_1]_\mathcal{B}+[\lambda_2v_2]_\mathcal{B}+\cdots+[\lambda_kv_k]_\mathcal{B}=0
		\end{equation*}
		Moreover, from statement 1 we can further reduce this to
		\begin{equation*}
			[\lambda_1v_1+\lambda_2v_2+\cdots+\lambda_kv_k]_\mathcal{B}=0
		\end{equation*}
		Finally, by using statement 3 we can see that this also equivalent to
		\begin{equation*}
			\lambda_1v_1+\lambda_2v_2+\cdots+\lambda_kv_k = 0
		\end{equation*}
		But by \pref{definition}{def-linear-independence} this is exactly what
		linear independence mean.
	\end{flushleft}
	\begin{flushleft}
		\proofleft: Assume that $\{v_1,v_2,\dots,v_k\}$ is linear independent,
		\textit{i.e.}
		\begin{equation*}
			\lambda_1v_1+\lambda_2v_2+\cdots+\lambda_kv_k = 0
		\end{equation*}
		Then the proof in this direction is using the same arguments as before in
		reversed order.
	\end{flushleft}
\end{proof}
